欢迎来到玛卡巴卡英文文档
Instructions

 Txt2img  Interface  Introduction:
1. Interface Overview
 
** Navigation area


￮	Text to image: Generate an image through the descriptive vocabulary

￮	Image generation: Generate an image by uploading a pre-defined image with a description vocabulary

￮	Partial modifications: Generate images by selecting areas and describing the vocabulary

Personal information 
￮	
Remaining inspiration points 

￮	Languages

￮	My Profile: see the history of the generation

￮	Log out


1.1 Preview
The image generated will be displayed here.
When the page is first opened, some of our pre-defined images will be displayed here.
1.2 Description
Here you can edit and enter the descriptors you want (guide)
1.3 Shortcut
Random: Some of the officially considered good "descriptors" will be added randomly into the description section.
Some of the officially considered good "descriptors" will be added randomly into the description section.
Empty: Clicking on this button will empty all the descriptors in the description area.
Advanced: Clicking on this button will show/hide the "Reverse Description Area", "Model Selection Area", "Parameter Selection Area", "Image Parameter Area "
1.4 Pre-set tag list
We will pre-set some of the pre-set tags for the user to choose from here.
1.5 Reverse description 
You can edit and enter the descriptors you want (tutorial on descriptors) here.
This function is mainly used when the AI plays randomly and may bring in various random contents, if you do not want it to appear in your painting
1.6 Model selection
You can choose between different styles of models here (currently only one model is available)
1.7 Parameter selection 
Number of images generated: the number of images generated in a single session
Number of steps to generate: the number of steps in a single calculation, 30-100 is recommended, the larger the value is, the finer the generated image will be and the more time it will consume
Text control strength:it is used to define how much control the description text has over the generated images. Generally around 7
Seed: when fixed, the same parameters will generate the same image each time
Automatic weighting: when selected, you can automatically weight some of the words in the description during the generation process, greatly improving the generation effect

1.8 Image parameters
Image Aspect ratio selection: the user can choose from three aspect ratios: 2:3, 1:1 and 3:2
Image Aspect selection: The different options represent the aspect resolution of the resulting image. M is for 768, L is for 1536, 3K is for 3072 and 6K is for 6144, the higher the resolution the higher the price of the generated image~.
Generate button: Generate. The small number next to it represents the number of points needed to generate this image.


 Img2img  Interface  Introduction:

1.Interface Overview
 
** Navigation area


￮	Text to image: Generate an image by describing the vocabulary

￮	Image to image: Generate an image by uploading a pre-defined image with a description words

￮	Partial modifications: Generate images by selecting areas and describing words

Personal information 
￮	
Remaining inspiration points 

￮	Language

￮	My Profile: see the history of the generation

￮	Log out
1.1 Preview
In the preview area you will be able to preview your uploaded image and the resulting image thumbnails

On the left hand side you will see the image you have uploaded and by default we will provide a demo for you to use

On the right hand side you will see the final image generated by using the description vocabulary together with the original image

You can switch between multiple images at the bottom right


1.2 Description
You can edit and enter the descriptors you want here (guide)
1.3 Shortcut 
Empty: Clicking on this button will empty all the descriptors in the "Description Area".
Advanced: Click on this button to show/hide the "Reverse description area", "Model selection area", "Parameter selection area", "Image parameter area "
1.4 Pre-set tag list
We will pre-set some of the pre-set tags for the user to choose from here.
1.5 Advanced function
Reverse Description

Here you can edit and enter your desired descriptor (tutorial on descriptors)
This function is mainly used when the AI is playing randomly, it may bring various random contents, if you do not want it to appear in your painting, you can enter here what you do not want to appear.

Model selection area

Here you can select different styles of models (currently only one model is available)
Generate quantity

The more you can generate, the more time and inspiration points you will need.
Number of steps to generate

The higher the number, the more detailed the image will be and the more time it will take.
Text control strength

Defines how much control the description text has over the generated image. Usually around 7
Seed

Fixed, the same parameters will generate the same image each time
Automatic weighting

When selected, some of the words in the description can be automatically weighted during the generation process, greatly improving the results.
Strength defines the strength of the modification to the original image, the higher the value the higher the strength


1.6 Upload and generate
Upload：Images can be uploaded to the server and displayed in the preview area using this function
Generate：Generate. The small number next to it represents the number of points needed for this generation.The number of points is proportional to the number of images generated and the resolution of the generated images

1.7 Do it yourself！
Let's try it out with this image from the demo
 
We wanted to add a little lens flare
￮	lens flare
Note: A very critical parameter in I2I is strength
 currently it is 0.9
 
Let's have a try
 
Well，it seems to be pushing too hard.
Except for  lens flare, which is a bit different from the original image.
It's okay, we change the strength parameter  to 0.6.
Remember what was mentioned above? The higher the strength value, the greater the 
modification.
 
Let's try to generate it again
 
OK, done, we added some effects to the original image.

Inpaint Interface  Introduction:
1. Interface Overview
 
The only difference between the inpaint and Img2img are in the editable operation, this introduction will not be introduced in other functions.

1.1 Operation area
With this function, users can click the mouse directly in this area and swipe to modify the area
 
 
As shown in the picture, I can work on the original image and can paint the area black

This function will only modify the inpaint area.

1.2 Line Width
Brush size, the size of the area that can be changed in a single pass when manipulating the manipulable area.
1.3 Do it yourself！

We can see the character's eyes on the demo image are blue and we change them into red.
 
We can use the balck brush function to do the inpaint on her eyes.
 
Then we add the key word "red eyes". OK. Now we click the Generate button.
 
Note: if the blushing area is too small, the unable generation problem will happen.
So, as you can see, we successfully change the eyes into red.
Instruction of Prompt
Basic Grammar：
The complete prompt consists of N tags, separated by commas, each tag belonging to a description of the current image.

The generation of a complete prompt for the base character includes：
￮	【basic】 ：Basics such as gender, hair and clothes
￮	【dynamic】 ：Orientation, body movement, expression
￮	【object】 ：Objects present on the scene, accessories present on the figure
￮	【detail】 ：Describe the level of detail in all of the above, e.g. the detail of the water, the delicate face, etc.
￮	【special effects】 ：Used to describe effects on scenes such as dynamic light, bloom, diffusion, velocity lines, etc.

A more detailed description will result in a generated image that is closer to the requirements.
For example：one girl, happy, long hair, red hair, suit, flowers
 
Highlights Features of TAG：
You can make some of your tags stand out in the picture by emphasising them with some special syntax：
￮	 {tag} :  increase the weight of tag by a factor of  1.05
￮	{tag}  : enlarges the weight of tag by a factor of  1.1 
￮	{tag} : decrease the weight of tag by 1.05 times

The superposition of multiple groups of stress symbols is represented as multiplication：
￮	{{tag}} : corresponding to a weight of 1.05*1.05  times
￮	((tag)) :  1.1*1.1 times the corresponding weight
￮	[tag] : corresponding weights reduced by  1.05*1.05 times

You can specify fixed weights in the form of tag:weights
￮	{tag: 1.5}, [tag: 1.5], (tag: 1.5), all of which represent a direct setting of that tag's weight to 1.5 times; adding more {}, [], () would be invalid under this syntax.
Each group of tags needs to be highlighted separately，such as
one girl, happy, long hair, red hair, {suit}, {flowers}
Error case：
one girl, happy, long hair, red hair, {suit, flowers}
Note：It is recommended that the weighting does not exceed 1.5, otherwise it will affect the overall look and feel of the image.
Let's see the results：
Plaintext
one girl, happy, long hair, red hair, suit, {flowers：1.5}
 
Have a try！
Basic
After getting familiar with the basic grammar operations, we have to start building our own exclusive AI creations.
For instance，if you want a warrior：
Plaintext
one boy, armor
 
If you want a warrior with a cloak：
Plaintext
one boy, armor, cloak
 
If you want a warrior with a cape, a crown and wings：
Plaintext
one boy, armor, cloak, feathered wings, crown
 
!!! Oh，Wait a minute, where are my wings? Don't panic, this is where you need tag emphasis.
Plaintext
one boy, armor, cloak, {feathered wings:1.3}, crown
 
Note:If you find the weighting adjustment troublesome or unfamiliar, please try the automatic weighting option we provide
[When automatic weighting is turned on, manually adjusted emphasis will not be valid, so please use caution!]
If you do not want a background, then you can do this.
Plaintext
one girl,armor,official art,simple background, fire
 
Want your anime scene? Then all you need to do is enter it like this：
Plaintext
a small 1girl holding an {umbrella} sitting alone on a {bench} after school. {{{masterpiece}}}, high quality, beautifully painted, pixiv, artstation hq, production art, comfort, [rain], reflective, dynamic light, cute, spring, 8k, {detailed face}, beautiful face, {bus stop}
 
Plaintext
high quality background detailed sky {rainforest} anime fantasy hd magical rain woods view from ground dirt moss masterpiece {{hyper realistic}} night stars moon pond river small fireflies best quality clear resolution
 
With cloak and crown, with wings refinement of the warrior base
Firstly, we add [Dynamic], where the character looks into the camera, the character smiles and raises one hand

Plaintext
one boy, armor, cloak, {feathered wings:1.3}, crown,Look at the camera, the characters smile and raise one hand
 
Then add [Object], Castle, Badge on chest
Plaintext
one boy, armor, cloak, {feathered wings:1.4}, crown,Look at the camera, the characters smile and raise one hand,Castle, {badge on chest:1.3}
 
Add [Detail] [Effects] again, delicate face, flame glow, diffusion, bubbles, floating feathers
Plaintext
one boy, armor, cloak, {feathered wings:1.4}, crown,Look at the camera, the characters smile and raise one hand,Castle, {badge on chest:1.3},Exquisite face, flame glow, diffusion, foam, floating feathers
 
How to flesh out a character or a scene by MKBK？
1.Constructing the general structure
Firstly，you should build a rough scene and characters in your mind (like the style in the picture below).
 
At this point, you should be able to imagine a simple descriptive word in your mind
A girl, blue hair, blue pupils, bikini swimming costume
A girl, blue hair, blue pupils, bikini
It's all relatively simple, let's try to generate it first
 
We'll get a picture like this, which is still very rudimentary at this point, so it's okay, let's go ahead and add a whole new vocabulary.

2Adding detailed descriptions
The whole structure has been successfully built, now we just need to add a whole new vocabulary of retouching classes to it

We have several steps for it：

1. What do you associate with the presence of the sea? Sea water, coconut trees, beach, sun, splash, bubbles, waves

2. Add an adjective to the base, such as dynamic light, floating hair, jewel-like eyes, diffuse, surround

3. Add a dynamic to this subject, facing the camera

Finally we will get： 
•	Facing the camera, beautiful water with details, bubbles, coconut trees, beach, dynamic light, floating hair, sunlight, splash, waves, jewel-like eyes, spread, surround

**We will add some of the adjectives to the instructions for the user to choose from, or you can modify them using the preset descriptions we provide (under construction)

Facing the camera, beautiful sea water with details, bubbles, coconuts, beaches, dynamic light, floating hair, sunlight, splash, waves, jewel like eyes, diffusion, surround
When adding descriptive words, we need to try to imagine what needs to be present in the scenario you have in mind

 
The results are again generated as shown above
At this point, you can see that the generated image has mostly met the conditions.
3.Modifying the description of the details
For example, if you want to have an image with long yellow hair，you could switch  to a new descriptive term "Long yellow hair" from  blue hair.
A girl, long yellow hair, blue pupils, bikini, facing the camera, beautiful sea water with details, bubbles, coconuts, beaches, dynamic light, floating hair, sunlight, splash, waves, jewel like eyes, diffusion, surround
 
If nothing else, we will have a picture of a girl with long hair.

Similarly, if you want to generate other content, you can add or modify it,.
4.Summary
In the process of generation, don't  imagine an overnight success, try to follow steps below：
1. give priority to describing the general appearance of the character (gender, hair, clothes, etc.)
2. describe the dynamics of the character, including orientation or body movements
3. describe the objects present on the scene (seawater, coconuts, shells, houses, etc.)
4. describe the level of detail of the objects, e.g. detailed water, real water, floating hair, etc.
5. repeat 2-4 to add or remove descriptive words
6. get a satisfactory picture

MAKABAKA Cup AI Painting Masters Competition Entry Instructions

Entry requirements
This competition is for internal test users only.
The competition is limited to Txt2img.
The competition is open only to images generated by yourself.
Entry pathway

During the competition period, we will have a submission button on the larger screen of Txt2img.
 
Detailed instructions
Users can only submit a total of 1 entry to the competition during the entire competition cycle. However, it is possible to make repeated submissions, taking only the most recent one.
There will be a second confirmation after clicking on the submission, and only after this confirmation will the submission actually be successful.

Note
All submissions will be screened for duplication and will not be accepted if the duplication rate exceeds 80%. This will be done after the deadline!
Competition process
From 25 November 00:00, a one-click submission will be added to the page (submission period: 25 November 00:00 - 27 November 18:00)
Submissions close at 18:00 on 27 November. We will use the time the image is received on the server.
On the 28th at 00:00, the ADG art students will select 50 images from all the entries for the final round.
The selected entries will be displayed on the Macabaca Square page (which will go live at 00.00 on the 28th) and will be voted on by all test users from 00.00 on the 28th to 24.00 on the 30th of November.
The interface will be divided into groups of 12 images and each group will have a maximum of 3 votes.
Each user will receive 12 votes per day (no accumulation) and will be refilled at 6am each day.
Until 30 November at 24.00 we will close the voting function and on 1 December at 10.00 we will announce the top 10 entries on the Square page.


Awards
First place: Cash prize of ¥500
Second place: ¥400 cash prize
Third place:Cash bonus ¥300
Fourth place: ¥200 in cash
Fifth to tenth place: ¥100 each
For the rest of you, your artwork will be made into a pillow or mug and sent to you.
 
 
Thank you for your support!
Wishing Pool
We will review your ideas on a daily basis, and those who are successfully included in the wish pool will receive an exclusive makabaka gift pack at the end of the beta!

 
Recommendations in the wishing pool so far：

[WIP] Fix the problem that fingers, limbs, etc. are not generated well (by Baka Makar)
[ETA 11.31] Support for automatic translation of Chinese descriptions into English descriptions (by Baka Makar)
[ETA 11.31] Support for quick map mode (by Bacamaca)
[ETA 11.20] Add map-generating and area-magic functions (by Bacamaca)
[✓] Add ability to generate in 4K resolution (by Bacamarca)
[✓] Show expected completion time of generated tasks (by Bacamarca)
[✓] Give descriptions of several presets (by Bacamarca)
[✓] Support for company email login (by Bacamarca)
[✓] Add Chinese translations for preset words (by Bacamarca)
[✓] Implement the first version of the secondary character + scene word generation function (by Bacamaca)



ChangeLog

Terms and conditions for users
•	Welcome to use MKBK!
This service is for internal algorithm development and testing purposes only. The service does not assume any legal responsibility for any results generated by the dissemination of user-generated images. The service reserves the right of final interpretation in case of any dispute arising from the use of the service. Users are prohibited from distributing any images generated by the Service outside the company. By registering, the user is deemed to agree to these terms and conditions and shall abide by not spreading illegal information such as pornography\violence, spreading false information, involving any military, political or other fields, or spreading statements that are contrary to socialist values.



